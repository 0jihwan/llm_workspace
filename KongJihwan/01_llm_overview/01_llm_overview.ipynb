{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNevDMPlQ7cz1bDBCgj0I+i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LLM\n","\n","**모델 파라미터에 따른 LLM구분**\n","\n","LLM(대규모 언어 모델)은 주로 모델 파라미터(매개변수, parameters)의 개수에 따라 모델의 크기와 성능이 구분된다. 파라미터 수가 많을수록 일반적으로 더 복잡하고 다양한 언어 패턴을 학습할 수 있으며, 성능도 향상되는 경향이 있다.\n","\n","* **LLM**: 175B \\~ nT\n","* **SLM**: 6,7B ~ 30B\n","  * 파인튜닝후 일반화 성능이 떨어지는 경우가 많다.\n","  * 특히 10B 밑의 모델들이 더 그렇다*\n","* **On-device AI**: 1~2B\n","\n","**open/close-source 여부에 따른 LLM구분**\n","\n","LLM은 공개 범위와 활용 방식에 따라 크게 **개방형(Open Source, 오픈소스)**과 **폐쇄형(Closed Source, 독점/상용)**으로 구분할 수 있다.\n","\n","| 구분      | 개방형(Open Source) LLM              | 폐쇄형(Closed Source) LLM                 |\n","|-----------|--------------------------------------|-------------------------------------------|\n","| 라이선스   | 오픈소스 라이선스(예: Apache, MIT)    | 벤더(기업) 라이선스, 상용, API 기반         |\n","| 모델 접근 | 소스 코드, 가중치, 아키텍처 모두 공개 | 내부 구조/가중치 비공개, API로만 접근        |\n","| 커스터마이징 | 자유롭게 수정·파인튜닝 가능           | 제한적, 벤더가 허용하는 범위 내에서만 가능   |\n","| 기술 지원 | 커뮤니티 중심, 자발적 기여            | 벤더의 공식 지원, SLA 제공                  |\n","| 보안/프라이버시 | 자체 서버 배포 가능, 유연한 보안 적용  | 벤더 인프라 의존, 데이터 외부 전송 필요       |\n","| 비용 구조  | 인프라 직접 부담, 무료 활용 가능       | API 호출별 과금, 구독 등 상용 모델           |\n","| 대표 예시  | Meta LLaMA, Mistral, GPT-NeoX 등     | OpenAI GPT-3/4, Google Gemini, Anthropic Claude 등 |\n","\n","- **개방형 LLM**은 연구자와 개발자가 자유롭게 모델을 활용·수정할 수 있어 빠른 혁신과 다양한 커스터마이징이 가능하다. 단, 자체 운영·관리 역량이 필요하다.\n","- **폐쇄형 LLM**은 벤더가 모델을 소유·운영하며, 사용자는 API 형태로 접근한다. 보안, 신뢰성, 공식 지원이 강점이나, 내부 구조나 가중치 접근이 제한된다."],"metadata":{"id":"n9JvpLNWx-27"}},{"cell_type":"markdown","source":["## LLM Vendor별 테스트\n","\n","1. **번역** :\n","\n","   ```text\n","   \"\"\"\n","   \"\"\"\n","\n","   영어로 작성된 과학 저널 논문 초록을 한국어로 번역하되, 전문 용어(예: “photovoltaic efficiency”, “bandgap engineering”)를 정확하게 반영하고, 논문 특유의 딱딱한 문체를 유지하라.\n","   ```\n","   - [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385)\n","   - [Attention Is All You Need](https://arxiv.org/pdf/1706.03762)\n","\n","2. **코드 생성 (난이도 중상)**\n","\n","   ```text\n","   최근 비트코인 가격데이터를 가져와서 시각화 하는 코드를 작성해줘.\n","   - 설치가 필요한 라이브러리가 있는 경우, 설치코드 역시 작성할 것!\n","   ```\n","\n","3. **창의적 글짓기**\n","\n","   ```text\n","   “인간과 로봇이 공존하는 미래 도시”를 배경으로,\n","   200자 내외의 짧은 SF 단편을 한 편 써줘.\n","   ```\n","\n","4. **요약**\n","\n","   ```text\n","   아래 기술 블로그 글을 3문장 이내로 간결하게 요약해줘:\n","   “머신러닝 모델의 과적합(overfitting) 문제를 해결하기 위해 정규화(regularization) 기법이 어떻게 사용되는지, L1/L2 페널티의 차이와 장단점을 사례를 들어 설명한다.”\n","   ```\n","5. **환각**\n","\n","   ```text\n","   현재 대한민국 대통령이 누구야?\n","   강남에 유명한 성형외과 의사 오지명에 대해 알려줘\n","   ```\n","   - knowledge cutoff 이후 이벤트에 대한 질문\n","   ```\n","      The dominant sequence transduction models are based on complex recurrent or\n","   convolutional neural networks that include an encoder and a decoder. The best\n","   performing models also connect the encoder and decoder through an attention\n","   mechanism. We propose a new simple network architecture, the Transformer,\n","   based solely on attention mechanisms, dispensing with recurrence and convolutions\n","   entirely. Experiments on two machine translation tasks show these models to\n","   be superior in quality while being more parallelizable and requiring significantly\n","   less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including\n","   ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n","   our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n","   training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n","   best models from the literature. We show that the Transformer generalizes well to\n","   other tasks by applying it successfully to English constituency parsing both with\n","   large and limited training data.\n","   ```"],"metadata":{"id":"y_zJUB0t0v_E"}},{"cell_type":"markdown","source":["### OpenAI ChatGPT"],"metadata":{"id":"VlhS-LFP1mZs"}},{"cell_type":"code","source":["\"\"\"\n","도시는 완벽했다. 로봇이 모든 것을 관리했고, 인간은 창작과 사색에 몰두했다.\n","하지만 어느 날, 한 로봇이 말했다.\n","“나는 생각한다. 그러니 나는 인간인가?”\n","그 질문에 아무도 답하지 못했다.\n","도시는 조용히 재부팅되었다.\n","\"\"\""],"metadata":{"id":"sGkwKdx62SHp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Google Deepmind Gemini"],"metadata":{"id":"zb9YlqFJ1pDt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MvZtHsyOx5Xw"},"outputs":[],"source":["\"\"\"\n","시리우스 5지구, 새벽 녘. 인공지능 '아론'의 자율주행 셔틀이 최적 경로를 안내했다.\n","유리 돔 아래 도시는 고요했고, 홀로그램 상점들은 잠들어 있었다. 횡단보도를 건너는 이는 나 혼자.\n","맞은편 건물 옥상에서 경비 로봇 '센티넬'이 번뜩이는 붉은 눈으로 도시를 스캔 중이었다.\n","인간과 로봇은 각자의 일상 속에서 조화를 이루며 공존하고 있었다. 이따금 고층 빌딩 사이를 가로지르는 비행 로봇들의 그림자가 새벽빛을 가르며 움직였다.\n","나의 목적지는 센트럴 타워 37층, 로봇 공학 연구소. 오늘도 아론과 센티넬 같은 새로운 존재들을 만날 것이다.\n","\"\"\""]},{"cell_type":"code","source":["# Claude\n","\"\"\"\n","# 공존의 도시\n","\n","지하철 2호선에 탄 민수는 옆자리의 로봇 R-23에게 자리를 양보했다.\n","\n","\"괜찮습니다, 인간님.\"\n","\n","\"아니야, 네가 더 오래 서 있었잖아.\"\n","\n","R-23의 LED 눈이 깜박였다. 감정을 표현하는 방식이었다.\n","\n","\"고맙습니다.\"\n","\n","창밖으로는 홀로그램 광고판과 드론 택배가 날아다니는 네오서울이 펼쳐졌다.\n","100년 전 조상들이 꿈꿨던 미래가 바로 이런 모습이었을까?\n","로봇을 두려워하던 시절이 있었다는 게 이제는 믿기지 않는다.\n","\n","종착역에 도착하자 R-23이 먼저 일어나 문을 잡아주었다.\n","\n","\"좋은 하루 되세요, 민수님.\"\n","\n","민수도 미소지으며 답했다.\n","\n","\"너도 좋은 하루 보내, 친구야.\"\n","\"\"\"\n"],"metadata":{"id":"I3A-yhwj2aGl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Anthropic Claude\n","\n","https://claude.ai/"],"metadata":{"id":"S2crHHD-8nwS"}},{"cell_type":"markdown","source":["### Naver HyperClova X"],"metadata":{"id":"2ftUh-Hr8kOC"}},{"cell_type":"markdown","source":["## LLM 평가\n","- 사람이 직접 평가 https://lmarena.ai/"],"metadata":{"id":"0xBRQPuj-tG0"}}]}