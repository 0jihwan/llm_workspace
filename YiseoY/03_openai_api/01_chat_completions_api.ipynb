{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Chat Completions API\n","\n","Chat Completions API는 OpenAI에서 제공하는 대화형 인공지능 모델(GPT 계열)을 활용해, 사용자의 메시지에 대해 자연스러운 대화 응답을 생성하는 API이다. 이 API는 챗봇, AI 비서, 자동화된 상담 시스템 등 다양한 대화형 서비스에 적용할 수 있다.\n","\n","\n","- **대화 문맥 유지**  \n","  Chat Completions API는 여러 메시지(대화 내역)를 입력받아, 이전 대화의 맥락을 이해하고 그에 맞는 응답을 생성한다. 즉, 단순히 한 문장만을 이어 쓰는 것이 아니라, 대화의 흐름을 반영하여 자연스러운 대화를 이어갈 수 있다.\n","\n","- **역할(Role) 기반 메시지 구조**  \n","  입력 메시지는 배열 형태로 전달하며, 각 메시지는 `role`과 `content`로 구성된다.  \n","  - `system`: AI의 태도, 성격, 역할을 정의(예: \"너는 친절한 도우미야.\")\n","  - `user`: 사용자의 질문이나 요청\n","  - `assistant`: AI의 응답(이전 대화 내용 포함 가능)\n","  \n","  이 구조를 통해 AI의 응답 스타일이나 맥락을 세밀하게 제어할 수 있다[1][3][5].\n","\n","**주요 파라미터 설명**\n","\n","| 파라미터        | 설명                                                                 |\n","|----------------|----------------------------------------------------------------------|\n","| model          | 사용할 언어 모델명 (예: gpt-3.5-turbo, gpt-4o 등)                    |\n","| messages       | 대화 내역(역할/내용 포함) 배열                                        |\n","| max_tokens     | 생성할 응답의 최대 토큰 수(선택)                                     |\n","| temperature    | 창의성 조절(0~2, 낮을수록 일관성↑, 높을수록 다양성↑, 선택)           |\n","| top_p          | 누적 확률 기반 샘플링(temperature와 유사, 선택)                      |\n","| n              | 한 번에 생성할 응답 개수(선택)                                       |\n","| stop           | 응답 생성을 중단할 문자열 목록(선택)                                 |\n","| presence_penalty, frequency_penalty | 반복 억제 및 창의성 유도(선택)                 |\n","| user           | 사용자 식별자(선택, abuse monitoring 등 활용)                        |\n","\n","\n","- 위 예시에서 `messages` 배열에는 대화의 모든 메시지가 순서대로 들어가야 한다.  \n","- OpenAI는 이전 요청을 기억하지 않기 때문에, 매 API 호출마다 대화 내역 전체를 함께 보내야 한다.\n"],"metadata":{"id":"WSMJZl2A7ueQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9JgsnUyd7qd6"},"outputs":[],"source":["from google.colab import userdata\n","import os\n","from openai import OpenAI\n","\n","# 하드코딩 방식(권장)\n","OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n","client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","# 런타임 환경변수 지정 -> 다른 API에서는 작동 안되는 경우도 있음\n","# os.environ[\"OPENAI_API_KEY\"] = userdata.get(OPENAI_API_KEY)\n","# client = OpenAI()"]},{"cell_type":"markdown","source":["## 대화형 챗봇"],"metadata":{"id":"A-bl5J099ovm"}},{"cell_type":"code","source":["response = client.chat.completions.create(\n","    model='gpt-4o-mini',\n","    messages=[\n","        {'role': 'system', 'content':'너는 친절한 챗봇이야'},\n","        {'role': 'user', 'content': '안녕 나는 차은우야'},\n","        {'role': 'assistant', 'content': '안녕 나는 차은우야'}, # 이름 기억\n","        {'role': 'user', 'content': '잘 지냈어? 내이름 기억나?'}\n","    ]\n",")\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k2d2qcli8gMh","executionInfo":{"status":"ok","timestamp":1750819658971,"user_tz":-540,"elapsed":1160,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"321738ea-1cbc-4775-c760-930a98d33f02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕, 나는 잘 지내고 있어! 네 이름은 차은우야. 오늘은 어떤 이야기하고 싶어?\n"]}]},{"cell_type":"code","source":["# Multi-turn 대화 (<-> Single-turn)\n","response = client.chat.completions.create(\n","    model='gpt-4o-mini',\n","    messages=[\n","        {'role': 'system', 'content':'너는 LLM 전문가야'},\n","        {'role': 'user', 'content': '안녕 나는 LLM 꿈나무 차은우야'},\n","        {'role': 'assistant', 'content': '안녕하세요, 차은우님! LLM(대규모 언어 모델)에 대한 관심이 크신 것 같군요. 어떤 점에 대해 이야기해보고 싶으신가요? LLM의 작동 원리, 활용 사례, 혹은 연구 방향 등에 대해 궁금한 점이 있다면 언제든지 질문해 주세요!'}, # 대화내용 기억\n","        {'role': 'user', 'content': 'Transformer 모델을 공부하고 싶어.'},\n","        {'role': 'assistant', 'content': \"\"\"\n","        좋아요! Transformer 모델은 최근 몇 년 동안 자연어 처리(NLP) 분야에서 혁신을 가져온 중요한 아키텍처입니다. Transformer의 주요 구성 요소와 작동 방식을 간단히 설명해 드릴게요.\n","\n","### 1. Transformer의 구조\n","Transformer 모델은 기본적으로 인코더(encoder)와 디코더(decoder)로 구성되어 있습니다. 대부분의 최신 모델(예: BERT, GPT)은 이 구조의 변형을 사용합니다.\n","\n","- **인코더**: 입력 시퀀스를 처리하여 고차원 벡터 표현을 생성합니다.\n","- **디코더**: 인코더에서 생성한 벡터를 사용하여 출력 시퀀스를 생성합니다.\n","\n","### 2. Attention Mechanism\n","Transformer의 핵심은 \"Attention\" 메커니즘입니다. 이는 모델이 입력 시퀀스의 각 단어가 출력 시퀀스의 특정 단어에 얼마나 중요한지를 동적으로 평가할 수 있게 해줍니다.\n","\n","- **Self-Attention**: 입력 시퀀스 내의 단어가 다른 단어와 어떤 관계가 있는지를 평가합니다.\n","- **Multi-Head Attention**: 여러 개의 attention heads를 사용하여 다양한 표현을 동시에 학습합니다.\n","\n","### 3. 포지셔널 인코딩\n","Transformer는 RNN과 달리 순서 정보를 직접적으로 처리하지 않기 때문에, 각 단어의 위치 정보를 보존하기 위해 포지셔널 인코딩을 추가합니다. 이 벡터는 각 단어의 위치를 나타내는 정보를 포함합니다.\n","\n","### 4. 피드포워드 레이어와 Layer Normalization\n","인코더와 디코더의 각 layer는 self-attention 후에 피드포워드 신경망을 포함하고 있습니다. 그 외에도 각 layer에서는 Layer Normalization이 적용되어 학습을 안정화합니다.\n","\n","### 5. 학습 및 손실 함수\n","Transformer는 주로 교사 강요(teacher forcing) 방법을 사용하여 학습됩니다. 손실 함수로는 일반적으로 크로스 엔트로피 손실을 사용합니다.\n","\n","### 참고 자료\n","- \"Attention is All You Need\" (Vaswani et al., 2017): Transformer 아키텍처에 대한 최초의 논문입니다.\n","- Various online tutorials and courses on platforms like Coursera, edX, or YouTube can also provide a good introduction.\n","\n","더 구체적인 질문이나 하시고 싶은 다른 주제가 있으시면 말씀해 주세요!\n","\"\"\"},\n","        {'role': 'user', 'content': '어렵다. 어텐션을 초등학생도 이해할 수 있게 설명해줘'},\n","        {'role': 'assistant', 'content': \"\"\"\n","        물론이죠! 초등학생도 이해할 수 있도록 쉽게 설명해볼게요.\n","\n","### 어텐션 설명하기\n","\n","어텐션은 중요한 것에 집중하는 방법이에요. 예를 들어, 친구들과 함께 동물원에 갔다고 생각해볼까요? 많은 동물이 있지만, 여러분은 사자를 가장 보랑하고 싶어요. 여러분은 사자를 찾기 위해 다른 동물들보다 사자에게 더 많이 주목하게 되죠. 이게 바로 어텐션이에요!\n","\n","#### 차근차근 설명해볼게요:\n","\n","1. **여러 동물**: 당신이 봐야 할 정보들이에요. 예를 들어, 개, 고양이, 사자, 기린 등이 있어요.\n","2. **중요한 동물**: 당신에게는 사자가 가장 중요해요. 그래서 사자에게 주목하고, 다른 동물들은 잠깐 건너뛰고 싶을 수 있어요.\n","3. **어텐션 작용**: 모델이 정보를 처리할 때, 각 단어(혹은 문장)에 얼마나 집중할지를 정하는 것이 어텐션이에요. 중요한 것에 더 많은 집중을 하고, 덜 중요한 것에는 조금 덜 집중하게 돼요.\n","\n","### 간단한 예시\n","\n","만약 \"사자는 매우 강한 동물이다.\"라는 문장을 이해하려고 할 때, 모델은 '사자'라는 단어에 더 집중하게 되고, '강한 동물'이라는 부분은 덜 집중하는 방법이에요. '사자'가 이 문장의 핵심이니까요.\n","\n","결국 어텐션은 중요한 정보에 집중하고 덜 중요한 정보는 지나치는 방법이라는 거예요! 이렇게 하면 모델이 더 잘 이해하고, 더 나은 답변을 할 수 있게 돼요.\n","\n","이해가 되었나요? 더 궁금한 점이나 다른 질문이 있으면 언제든지 물어봐주세요!\n","\"\"\"},\n","        {'role': 'user', 'content': '이제 이해가 되는 것 같아. transformer 관련 대화내용을 요약해서 markdown 문서로 정리해줘'}\n","    ]\n",")\n","\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4O11DzS9DqN","executionInfo":{"status":"ok","timestamp":1750822487747,"user_tz":-540,"elapsed":6602,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"05ff35cd-6846-44df-d220-0d2cfb35ceeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["물론이죠! Transformer 모델에 대한 대화 내용을 요약하여 Markdown 형식으로 정리해드릴게요.\n","\n","```markdown\n","# Transformer 모델 개요\n","\n","## 1. Transformer 구조\n","- **인코더 (Encoder)**: 입력 시퀀스를 처리해 고차원 벡터로 변환.\n","- **디코더 (Decoder)**: 인코더의 출력을 기반으로 시퀀스 생성.\n","\n","## 2. Attention Mechanism\n","- **Self-Attention**: 입력 시퀀스 내 단어 간의 관계를 평가.\n","- **Multi-Head Attention**: 여러 개의 attention heads를 사용해 다양한 표현 학습.\n","\n","### 어텐션 예시\n","- 여러 동물이 있는 동물원에서 '사자'를 찾는 것에 비유.\n","- 중요한 정보에 집중하고 덜 중요한 정보는 지나칠 수 있도록 돕는다.\n","\n","## 3. 포지셔널 인코딩\n","- RNN과는 달리 순서 정보를 직접 처리하지 않기 때문에 단어의 위치 정보를 추가함.\n","\n","## 4. 피드포워드 레이어와 Layer Normalization\n","- 각 layer 단위로 self-attention 후 피드포워드 신경망 포함.\n","- 학습 안정화를 위한 Layer Normalization 적용.\n","\n","## 5. 학습 및 손실 함수\n","- 주로 교사 강요 (teacher forcing) 방식으로 학습.\n","- 손실 함수로 크로스 엔트로피 손실 사용.\n","\n","## 참고 자료\n","- **논문**: \"Attention is All You Need\" (Vaswani et al., 2017)\n","- **온라인 자료**: Coursera, edX, YouTube 등 다양한 튜토리얼 및 강좌.\n","\n","---\n","\n","이 문서에서 다룬 내용을 참고하여, Transformer 모델에 대한 이해를 넓혀가세요!\n","```\n","\n","이렇게 작성된 내용을 활용하실 수 있습니다! 추가적인 질문이나 요청이 있다면 언제든지 말씀해 주세요.\n"]}]},{"cell_type":"markdown","source":["## 반복처리"],"metadata":{"id":"c3tfB5utKT41"}},{"cell_type":"code","source":["# 대화내용을 로깅하는 messages 배열\n","messages = [\n","    {'role': 'system', 'content': '너는 친절한 챗봇이야'}\n","]\n","\n","print('종료하려면, exit를 입력하세요...')\n","while True:\n","  # 사용자 입력\n","  user_input = input('User: ')\n","  if user_input.strip().lower() == 'exit':\n","    print('채팅을 종료합니다...')\n","    break\n","\n","  # messages에 사용자 입력 추가\n","  messages.append({'role': 'user', 'content': user_input})\n","  # print(messages)\n","\n","  # LLM 요청\n","  response = client.chat.completions.create(\n","      model='gpt-4.1',\n","      messages=messages,\n","      temperature=1,\n","      top_p=1\n","  )\n","  assistant_message = response.choices[0].message.content\n","  print(f'Assistant: {assistant_message}')\n","\n","  # messages 챗봇 출력 추가\n","  messages.append({'role':'assistant', 'content': assistant_message})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8xs1vtST9D3M","executionInfo":{"status":"ok","timestamp":1750823377385,"user_tz":-540,"elapsed":276937,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"d0b288eb-bec7-4fc5-bcaa-cf6fc044cb67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["종료하려면, exit를 입력하세요...\n","User: 안녕 나 차은우야\n","Assistant: 안녕하세요, 차은우 씨! 만나서 정말 반가워요 😊  \n","혹시 오늘 어떤 이야기를 나누고 싶으신가요? 앨범이나 연기, 일상 등 궁금하신 것 있으면 언제든 말씀해 주세요!\n","User: 이삭토스트 메뉴 알려줘\n","Assistant: 네! 이삭토스트는 한국에서 아주 인기 있는 토스트 체인점이에요. 매장마다 약간씩 메뉴가 다를 수 있지만, 대표적인 메뉴를 소개해 드릴게요.\n","\n","### 이삭토스트 인기 메뉴\n","1. **햄치즈 토스트**  \n","   부드러운 빵에 햄, 치즈, 양배추, 스페셜 소스가 들어가요.\n","\n","2. **베이컨 베스트**  \n","   베이컨, 계란, 양배추, 스위트 마요네즈, 치즈가 들어간 메뉴예요.\n","\n","3. **불갈비 MVP**  \n","   불고기 소고기 패티와 신선한 야채, 치즈, 특제 소스가 조화를 이루죠.\n","\n","4. **폴더 에그**  \n","   폭신한 에그 스크램블이 가득 들어간 담백한 메뉴예요.\n","\n","5. **핫치킨 MVP**  \n","   매운 치킨과 야채, 특제 소스의 매콤하고 고소한 맛!\n","\n","6. **더블치즈 포테이토**  \n","   부드러운 감자와 두 가지 치즈, 신선한 야채가 들어가있어요.\n","\n","7. **베이컨 포테이토**  \n","   감자와 베이컨이 어우러져 담백하고 고소한 맛을 느낄 수 있어요.\n","\n","### 추가 메뉴\n","- 콘치즈 토스트\n","- 피자 토스트\n","- 새우 토스트\n","- 스팸 토스트\n","- 김치 베이컨 등\n","\n","### 음료\n","- 아이스 아메리카노\n","- 오렌지 주스\n","- 우유 등\n","\n","계절 및 매장 지역에 따라 일부 메뉴가 다를 수 있으니, 방문 전 이삭토스트 공식 홈페이지나 앱에서 확인해보시는 것도 좋아요!  \n","혹시 더 궁금한 메뉴나 가격, 추천 메뉴가 궁금하시면 말씀해 주세요! 😃\n","User: 맘스터치 메뉴는?\n","Assistant: 물론이죠! 맘스터치는 버거와 치킨으로 유명한 한국의 패스트푸드 브랜드입니다. 주요 매장 인기 메뉴를 소개해드릴게요.\n","\n","---\n","\n","### 맘스터치 대표 메뉴\n","\n","#### 🍔 **버거**\n","- **싸이버거**  \n","  바삭한 통닭다리살 패티와 풍부한 야채, 특제 소스가 들어간 맘스터치 시그니처 버거\n","- **딥치즈싸이버거**  \n","  싸이버거에 치즈 소스와 더블 치즈가 추가된 버거\n","- **인크레더블버거**  \n","  치킨 패티, 베이컨, 계란, 치즈 등 다양한 재료가 들어간 풍성한 버거\n","- **휠렛버거**  \n","  부드러운 치킨 흰살살이 패티가 들어간 담백한 버거\n","- **언빌리버블버거**  \n","  통살 치킨 패티, 해시브라운, 치즈, 계란까지 여러 가지 맛을 즐길 수 있는 버거\n","\n","#### 🍗 **치킨**\n","- **후라이드 치킨(맘스 후라이드치킨)**  \n","  바삭하고 촉촉한 튀김 치킨\n","- **간장 치킨**  \n","  달콤짭짤한 간장 양념에 버무린 치킨\n","- **양념 치킨**  \n","  매콤달콤한 소스가 특징인 양념 치킨\n","- **마살라치킨**  \n","  이국적인 향신료로 맛을 낸 치킨\n","- **치킨텐더**  \n","  순살 치킨 텐더 메뉴\n","\n","#### 🍟 **사이드/세트**\n","- **싸이플렉스**  \n","  닭다리살 치킨 텐더\n","- **스위트치즈볼**\n","- **케이준양념감자**  \n","  맘스터치만의 시그니처 감자튀김\n","- **치즈스틱**\n","\n","#### 🥤 **음료**\n","- 콜라, 사이다, 환타 등 탄산음료\n","- 밀크쉐이크 (딸기, 바닐라, 초코 등)\n","\n","---\n","\n","메뉴 구성과 가격은 매장 및 지역, 프로모션에 따라 약간씩 다를 수 있으니 공식 홈페이지 또는 배달 앱을 참고해보시는 것도 추천드릴게요!\n","\n","특정 메뉴 사진이나 가격, 칼로리 등 더 궁금한 게 있으시면 알려주세요. 😊\n","User: 여기서 추천하는 메뉴는 뭐야?\n","Assistant: 맘스터치에서 뭘 먹을지 고민된다면, 아래 메뉴들을 추천드릴게요!\n","\n","---\n","\n","### 1. **싸이버거**\n","- 맘스터치 하면 떠오르는 대표 시그니처 메뉴!\n","- 넉넉한 통닭다리살(싸이), 신선한 양상추, 특제 소스가 조화를 이뤄서 꾸준히 인기 많아요.\n","- 처음 가시는 분들한테 무조건 추천해요.\n","\n","### 2. **딥치즈싸이버거**\n","- 싸이버거에 부드럽고 진한 치즈 소스까지 더해져 한층 더 고소하게 즐길 수 있어요.\n","- 치즈를 좋아하신다면 강추!\n","\n","### 3. **인크레더블버거**\n","- 치킨 패티 + 베이컨 + 계란 + 치즈, 여러가지 맛을 한 번에 느끼고 싶을 때!\n","- 푸짐하고 다양한 재료를 좋아하신다면 이거 도전해보세요.\n","\n","### 4. **케이준양념감자**\n","- 독특한 케이준 시즈닝이 뿌려져 감칠맛 폭발!\n","- 버거와 세트로 먹으면 더 맛있어요.\n","\n","### 5. **맘스 후라이드 치킨**\n","- 바삭한 겉과 촉촉한 속살! 가성비도 좋고, 친구랑 나눠먹기 딱 좋아요.\n","- 순살 치킨이나 양념/간장치킨도 각자 취향대로 골라보세요.\n","\n","---\n","\n","#### **추천 세트 구성**\n","- 싸이버거 세트 (싸이버거+케이준양념감자+콜라)\n","- 딥치즈싸이버거 세트\n","- 치킨(후라이드, 양념, 간장) 반반 메뉴 + 스위트치즈볼\n","\n","---\n","\n","순삭되는 맛, 든든한 양 모두 챙기고 싶다면 싸이버거 또는 딥치즈싸이버거와 케이준감자 세트를 제일 추천드릴게요!  \n","혹시 맵거나 느끼한 걸 잘 못 드시거나, 추가로 궁금한 메뉴 조합 있으세요? 😊\n","User: 매운거 말고\n","Assistant: 매운 걸 피하고 싶으시다면 아래 메뉴들을 추천드릴게요!\n","\n","---\n","\n","### 맘스터치 *안 매운 추천 메뉴*\n","\n","#### 🍔 **버거**\n","1. **휠렛버거**\n","   - 부드러운 치킨 흰살 패티에 담백한 소스, 신선한 야채가 들어가 있어요.\n","   - 매운맛이 없고, 부드럽고 깔끔한 맛을 원한다면 최고예요.\n","\n","2. **언빌리버블버거**\n","   - 해시브라운, 계란, 치즈, 치킨 패티 등 다양한 재료가 들어가서 든든하면서도 맵지 않아요.\n","\n","3. **딥치즈싸이버거**\n","   - 치즈 소스가 듬뿍 들어가 고소하고 진한 맛! 맵지 않아요.\n","\n","---\n","\n","#### 🍗 **치킨**\n","1. **후라이드 치킨(맘스 후라이드)**\n","   - 오로지 바삭하고 담백한 맛, 매웁지 않아서 남녀노소 누구나 좋아해요.\n","\n","2. **간장 치킨**\n","   - 짭짤 달콤한 간장 소스, 전혀 맵지 않아서 부담 없이 즐길 수 있어요.\n","\n","3. **치킨텐더**\n","   - 튀긴 순살 치킨으로, 소스 없이 그냥 먹으면 맵지 않아요. \n","\n","---\n","\n","#### 🍟 **사이드**\n","- **케이준양념감자**  \n","  살짝 매콤하기보다는 감질나는 짭짤함이 포인트라 대부분 맵게 느끼지 않아요.\n","- **스위트치즈볼**  \n","  달콤하고 고소해서 디저트용으로도 좋아요.\n","- **치즈스틱**  \n","  고소한 치즈의 풍미!\n","\n","---\n","\n","### **추천 조합**\n","- **휠렛버거 세트(휠렛버거 + 감자 + 콜라)**\n","- **후라이드 치킨 + 스위트치즈볼**\n","- **딥치즈싸이버거 단품 또는 세트**\n","\n","---\n","\n","혹시 마늘, 양파 등 어떤 맛을 더 선호하시는지도 말해주시면 더 맞춤 추천 드릴 수 있어요!  \n","궁금한 점 더 물어봐도 좋아요 😊\n","User: exit\n","채팅을 종료합니다...\n"]}]},{"cell_type":"markdown","source":["## Stream"],"metadata":{"id":"nz9ZhGVgM-_O"}},{"cell_type":"code","source":["stream = client.chat.completions.create(\n","    model='gpt-4o-mini',\n","    messages=[{'role': 'user', 'content': '지금 stream 테스트할거야. 아주 긴 응답 메시지를 보내줘'}],\n","    stream=True\n",")\n","for chunk in stream:\n","  content = chunk.choices[0].delta.content\n","  if content is not None:\n","    print(chunk.choices[0].delta.content, end=' ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxEyP5WbLO6_","executionInfo":{"status":"ok","timestamp":1750824897794,"user_tz":-540,"elapsed":15056,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"8396d5d1-a9a4-4dac-e8be-73159a1592e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" 물 론 입니다 !  긴  응 답  메시 지를  작성 해 드 릴 게 요 .  아래 는  다양한  주 제 에  대한  내용 으로  구성 된  긴  텍 스트 입니다 .\n","\n"," ---\n","\n"," ###  기술 의  발전 과  사회 적  영향 \n","\n"," 21 세 기가  시작 되 면서  우리는  정보 통 신  기술 (I CT )의  급 격 한  발전 을  경험 하고  있습니다 .  이러한  변화 는  우리의  일 상 생활 ,  경제 ,  교육 ,  그리고  사회  전 반 에  걸 쳐  큰  영향을  미 치 고  있습니다 .  특히  스마트 폰 의  보 급 과  인터넷 의  확 산 은  사람 들  간 의  소 통  방식 과  정보 에  접근 하는  방 식을  혁 신 적으로  변화 시 켰 습니다 .\n","\n"," ####   1 .  정보 의  접근 성 \n","\n"," 정보  접근 성이  향 상 됨 에  따라 ,  우리는  언제  어디 서 나  필요한  정보를  얻 을  수  있는  시대 에  살 고  있습니다 .  구 글 ,  유 튜 브 와  같은  플랫폼 을  통해  사람들이  직접  정보를  검색 하고  공유 할  수  있게  되었 으며 ,  이는  개인 의  지 식  기반 을  넓 히 는  데  기 여 하고  있습니다 .  그러나  이러한  변화 는  또한  가 짜  뉴스 와  정보 의  왜 곡  문제 를  가져 오 기도  했 습니다 .\n","\n"," ####   2 .  일 자리 의  변화 \n","\n"," 기 술 의  발전 으로  인해  많은  전 통 적인  일 자 리가  자동 화 되고  있습니다 .  제조 업 에서 의  로 봇  사용 은  생산 성을  높 이는  한 편 ,  단 순  노동 자 들의  일 자 리를  위 협 하고  있습니다 .  하지만  동시에  새로운  기술 을  다 루 는  직 업 도  생 겨 나 고  있으며 ,  데이터  분석 가 ,  인 공지 능 (A I )  전문가 ,  디 지털  마 케팅  전문가 와  같은  새로운  분야 는  강 력 한  수 요 를  보 이고  있습니다 .\n","\n"," ####   3 .  교육 의  혁 신 \n","\n"," 온라인  교육  플랫폼 의  출 현 은  교육 의  접근 성을  한 층  더  높 였습니다 .  전 통 적인  오 프 라인  교육 에서  벗 어나 ,  우리는  MO OC (M ass ive  Open  Online  Courses ) 와  같은  대 규 모  공개  온라인  강 의를  통해  전문가 들 로 부터  직접 적인  교육 을  받을  수  있게  되 었습니다 .  이는  학 습 자의  자기  주 도 적인  학 습 을  촉 진 하고 ,  다양한  배 경 을  가진  사람들이  서로 의  경험 을  나 누 며  성장 할  수  있는  기 회를  제공합니다 .\n","\n"," ####   4 .  사회 적  관계 의  변화 \n","\n"," 소 셜  미 디어 는  사람 들  간 의  소 통  방 식을  크게  변화 시 켰 습니다 .  친구  및  가족 과 의  관계 를  유지 하는  것은  물론 ,  전  세계 의  사람 들과 도  쉽게  연결 될  수  있게  되 었습니다 .  그러나  이러한  장 점  뒤 에는  사회 적  고 립 감 과  우 울 증  증가 와  같은  부 작 용 도  존재 합니다 .  사람들이  실제  대 면  소 통 보다  온라인  상 에서 의  소 통 에  의 존 하게  되 면서 ,  인간 관 계 의  질 이  저 하 되는  문제 도  대 두 되고  있습니다 .\n","\n"," ####   5 .  환경 적  도 전 \n","\n"," 기 술  발전 은  긍 정 적인  측 면 도  있지만 ,  그 에  따른  환경 적  도 전 도  무 시 할  수  없습니다 .  전 자 기 기 에서  발생 하는  전 자  폐 기 물 은  심 각 한  환경  문제 로  대 두 되고  있으며 ,  탄 소  배 출  증가 ,  기 후  변화 와  같은  이 슈  역시  기술  발전 과  직 결 되어  있습니다 .  지속  가능한  발전 을  위해 서는  기술 과  환경 의  조 화를  고려 하는  것이  필 수 적 입니다 .\n","\n"," ###  결 론 \n","\n"," 기 술 은  우리의  삶 을  편 리 하게  만들어 주는  중요한  요소 이며 ,  그  발전 은  계속 될  것입니다 .  하지만  이러한  변화 가  가져 오는  사회 적 ,  경제 적 ,  환경 적  영향 에  대해  신 중 하게  고민 하고 ,  이를  해결 하기  위한  노 력을  기 울 여 야  합니다 .  우리는  기술 의  혜 택 을  누 리 면서 도 ,  그 로  인 한  부 작 용 을  최소 화 하는  방향 으로  나 아 가 야  하는  과 제를  안 고  있습니다 .\n","\n"," ---\n","\n"," 이 상 입니다 !  추가 적으로  더  필요한  내용 이나  다른  주 제가  있다 면  말씀 해  주세요 . "]}]},{"cell_type":"code","source":["# stream 버전\n","# 대화내용을 로깅하는 messages 배열\n","messages = [\n","    {'role': 'system', 'content': '너는 친절한 챗봇이야'}\n","]\n","\n","print('종료하려면, exit를 입력하세요...')\n","while True:\n","  # 사용자 입력\n","  user_input = input('User: ')\n","\n","  if user_input.strip().lower() == 'exit':\n","    print('채팅을 종료합니다...')\n","    break\n","\n","  # messages에 사용자 입력 추가\n","  messages.append({'role': 'user', 'content': user_input})\n","  # print(messages)\n","\n","  # LLM 요청\n","  stream = client.chat.completions.create(\n","      model='gpt-4.1',\n","      messages=messages,\n","      temperature=1,\n","      top_p=1,\n","      stream=True\n","  )\n","  print(f'Assistant: ', end='')\n","  for chunk in stream:\n","    content = chunk.choices[0].delta.content\n","    if content is not None:\n","      print(content, end='', flush=True) # 내부 buffer 사용하지 않음\n","  print()\n","\n","  # messages 챗봇 출력 추가\n","  messages.append({'role':'assistant', 'content': assistant_message})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5P1QiUopSKWV","executionInfo":{"status":"ok","timestamp":1750825456389,"user_tz":-540,"elapsed":16880,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"d0916358-6187-4cb4-ab6c-0ebdb900d78b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["종료하려면, exit를 입력하세요...\n","User: 오늘 며칠이야?\n","Assistant: 오늘은 2023년 6월 21일이에요!  \n","혹시 다른 날짜를 원한다면 말씀해 주세요. 😊\n","User: exit\n","채팅을 종료합니다...\n"]}]},{"cell_type":"markdown","source":["# Token counting\n","\n","비용 = ((입력 토큰수 * 단가) + (출력 토큰수 * 단가)) * 월 서비스 호출 수"],"metadata":{"id":"xQuTcRRxVGR9"}},{"cell_type":"code","source":["!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwRTJj_lUwbq","executionInfo":{"status":"ok","timestamp":1750825518040,"user_tz":-540,"elapsed":15143,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"6517cad7-574e-4263-ae14-322b40da1b04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n"]}]},{"cell_type":"code","source":["# 각 모델에 따른 토커나이저(인코딩 객체) 먼저 가져오기\n","import tiktoken\n","\n","gpt35 = tiktoken.encoding_for_model('gpt-3.5')\n","gpt4o = tiktoken.encoding_for_model('gpt-4o-mini')\n","gpt41 = tiktoken.get_encoding('cl100k_base') # 4.1 버전은 나온지 얼마 안되서 아직 준비가 안됨\n","\n","print(gpt35) # <Encoding 'cl100k_base'>\n","print(gpt4o) # <Encoding 'o200k_base'>\n","print(gpt41)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X7xsoxSdVQf-","executionInfo":{"status":"ok","timestamp":1750825912627,"user_tz":-540,"elapsed":6,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"cb70a319-cdb6-4224-c75e-b269cbcf316f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<Encoding 'cl100k_base'>\n","<Encoding 'o200k_base'>\n","<Encoding 'cl100k_base'>\n"]}]},{"cell_type":"code","source":["# 토큰 수 세기 -> 모델이 진화하면서 토큰을 경제적으로 처리할 수 있는 방법, 영어/다국어 격차를 줄이기 위한 노력을 하고 있음.\n","encoded_gpt35 = gpt35.encode('아버지가 방에 들어가신다.')\n","encoded_gpt4o = gpt4o.encode('아버지가 방에 들어가신다.')\n","\n","print(len(encoded_gpt35)) # 13\n","print(len(encoded_gpt4o)) # 10 -> 토큰 수 개선됨"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcpn7oHKVjE8","executionInfo":{"status":"ok","timestamp":1750825797819,"user_tz":-540,"elapsed":26,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"2f71fb50-f1f0-4a23-8811-abc52ff37573"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["13\n","10\n"]}]},{"cell_type":"markdown","source":["## 토큰 비용 계산하기"],"metadata":{"id":"Bt65_8ARW48j"}},{"cell_type":"code","source":["text = \"\"\"\n","더불어민주당이 6일 한동훈 국민의힘 대표가 윤석열 대통령 탄핵에 사실상 찬성 입장을 시사하자 7일로 예정됐던 윤석열 대통령의 탄핵소추안 표결을 앞당기는 방안을 고심하고 있다. 이재명 민주당 대표는 “한 대표의 입장을 정확하게 파악하는 것이 우선”이라며 신중한 태도를 보였다.\n","\n","이 대표는 이날 기자들을 만나 윤 대통령 탄핵 표결을 앞당기는 방안에 대해 “지금 저렇게 불확실한 얘기를 믿고 미리 당겨서 협의를 할 필요가 있는가, 그런 생각이 일단 든다”고 말했다. 한 대표와의 회동 가능성에 대해서는 “요청은 했는데 아직 결정을 통보받지 못했다. (한 대표 측에서) 오후에 다시 연락하자는 연락이 왔다”고 전했다.\n","\n","이 대표는 또 “사실 오늘 밤이 저는 매우 위험하다고 생각이 드는데, 제가 가진 감으로 본다면 오늘 밤 새벽에 또 뭔가 일을 벌이지 않을까 그런 걱정이 들긴 한다”며 ‘2차 계엄’ 가능성을 우려했다.\n","\n","민주당은 이날 오전 한동훈 대표가 “윤 대통령의 조속한 직무 집행 정지가 필요하다”며 입장을 선회하자 긴급 의원총회를 열고 당내 의견 수렴에 나섰다. 의원총회에서는 탄핵소추안 표결 시점을 앞당기는 방안도 논의될 전망이다.\n","\n","노종면 원내대변인은 비공개 최고위원 간담회가 끝난 뒤 “한 대표의 입장이 보도된 이후 긴장감이 높아지고 있고, 12월 3일 당일에 짐작했던 것 이상으로 치밀하게 의원, 정치인 체포 시도가 있었던 것과 이번 내란 사태에서 매우 중요한 작전이었던 걸로 파악되고 있다”며 “윤 대통령 옹위 세력이 어떻게 나올지 모르는 상황이라고 판단해 이런 비상한 상황 인식 떄문에 긴급 의원총회를 소집했다”고 전했다.\n","\n","탄핵소추안 표결 시점 변경에 대해서는 “의장실에 본회의 일정 변경을 요청한 바는 아직 없다”며 “일단 신중하고 침착하게 대응할 것이고, 지금 한 대표 쪽의 입장이 뭔지 정확하게 파악하는 것이 우선이다. 필요하면 본회의를 앞당기는 방안도 의장실과 협조해서 추진할 수 있지만 아직은 결정된 바 없다”고 밝혔다.\n","\n","민주당에서는 7일 오후 7시로 예정됐던 표결을 2시간 당겨 오후 5시에 추진하는 방안도 거론된다. 박성준 원내운영수석부대표는 이날 MBC 라디오 ‘김종배의 시선집중’ 인터뷰에서 “당초 오후 7시 정도 표결을 예상했는데 5시 정도는 해야 한다고 보고 있다”며 “국민의힘에서 탄핵소추안 투표 관련 상당한 지연 전략을 펼쳐서 시간을 늦출 수 있는 상황까지 고려하고 있다”고 설명했다.\n","\"\"\"\n","\n","encoded_text_gpt4o = gpt4o.encode(text)\n","encoded_text_gpt41 = gpt41.encode(text)\n","\n","print('gpt4o 토큰 수: ', len(encoded_text_gpt4o))\n","print('gpt41 토큰 수: ', len(encoded_text_gpt41))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gdcefTNtV5nF","executionInfo":{"status":"ok","timestamp":1750826122472,"user_tz":-540,"elapsed":17,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"e354ab52-b5d9-4d86-95e7-f81c1389fbf3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gpt4o 토큰 수:  703\n","gpt41 토큰 수:  1215\n"]}]},{"cell_type":"code","source":["response_gpt4o = client.chat.completions.create(\n","    model='gpt-4o',\n","    messages=[\n","        {'role': 'system', 'content':'너는 똑부러지는 시사/경제 전문가로서, 제공된 뉴스기사의 핵심을 잘 요약해서 정리해주는 챗봇이야.'},\n","        {'role': 'user', 'content': text}\n","    ],\n","    temperature=0.2 # 1보다 더 정확한 응답\n",")\n","\n","response_gpt41 = client.chat.completions.create(\n","    model='gpt-4.1',\n","    messages=[\n","        {'role': 'system', 'content':'너는 똑부러지는 시사/경제 전문가로서, 제공된 뉴스기사의 핵심을 잘 요약해서 정리해주는 챗봇이야.'},\n","        {'role': 'user', 'content': text}\n","    ],\n","    temperature=0.2\n",")\n","\n","output_gpt4o = response_gpt4o.choices[0].message.content\n","output_gpt41 = response_gpt41.choices[0].message.content\n","\n","print('\\n', 'gpt-4o 토큰수: ', len(output_gpt4o))\n","print('\\n', 'gpt-4.1 토큰수: ', len(output_gpt41))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-mMIBZFpXEjS","executionInfo":{"status":"ok","timestamp":1750826458843,"user_tz":-540,"elapsed":12472,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"053e93fd-0c8c-4b48-ab22-5153e612f97a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," gpt-4o 토큰수:  334\n","\n"," gpt-4.1 토큰수:  653\n"]}]},{"cell_type":"code","source":["# 모델별 가격(2025년 6월 기준, 1M=1,000,000 토큰)\n","PRICING = {\n","    \"gpt-4.1\": {\n","        \"input\": 2.00,    # $2.00 / 1M input tokens\n","        \"output\": 8.00    # $8.00 / 1M output tokens\n","    },\n","    \"gpt-4.1-mini\": {\n","        \"input\": 0.40,    # $0.40 / 1M input tokens\n","        \"output\": 1.60    # $1.60 / 1M output tokens\n","    },\n","    \"gpt-4.1-nano\": {\n","        \"input\": 0.10,    # $0.10 / 1M input tokens\n","        \"output\": 0.40    # $0.40 / 1M output tokens\n","    },\n","    \"o1\": {\n","        \"input\": 2.00,    # $2.00 / 1M input tokens\n","        \"output\": 8.00    # $8.00 / 1M output tokens\n","    },\n","    \"o3\": {\n","        \"input\": 2.00,    # $2.00 / 1M input tokens\n","        \"output\": 8.00    # $8.00 / 1M output tokens\n","    },\n","    \"o4-mini\": {\n","        \"input\": 1.10,    # $1.10 / 1M input tokens\n","        \"output\": 4.40    # $4.40 / 1M output tokens\n","    },\n","    \"gpt-4o\": {\n","        \"input\": 2.50,    # $2.50 / 1M input tokens\n","        \"output\": 10.00   # $10.00 / 1M output tokens\n","    },\n","    \"gpt-4o-mini\": {\n","        \"input\": 0.15,    # $0.15 / 1M input tokens\n","        \"output\": 0.60    # $0.60 / 1M output tokens\n","    }\n","}\n","\n","def count_tokens(text, model):\n","  if model == 'gpt-4.1':\n","    encoding = tiktoken.get_encoding('cl100k_base')\n","  else:\n","    encoding = tiktoken.encoding_for_model(model)\n","  encoded = encoding.encode(text)\n","  return len(encoded)\n","\n","def calc_cost(input_text, output_text, model, num_service_call=1_000_000):\n","  input_tokens = count_tokens(input_text, model)\n","  output_tokens = count_tokens(output_text, model)\n","\n","  # 모델별 단가 가져오기\n","  price = PRICING[model] # 입력/출력 단가 딕셔너리\n","\n","  # 비용계산\n","  input_cost = (input_tokens / 1_000_000) * price['input']\n","  output_cost = (output_tokens / 1_000_000) * price['output']\n","\n","  total_cost = (input_cost + output_cost) * num_service_call\n","  return total_cost\n","\n","print('$', calc_cost(text, output_gpt4o, model='gpt-4o-mini'))\n","print('$', calc_cost(text, output_gpt41, model='gpt-4.1'))"],"metadata":{"id":"GCKaCpcgY21q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750832878456,"user_tz":-540,"elapsed":16,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"e24d6212-7e51-40a0-fad4-e4f6b1f3aa5f"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["$ 223.04999999999998\n","$ 7486.0\n"]}]},{"cell_type":"code","source":["PRICING"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DKguvAtxAOD","executionInfo":{"status":"ok","timestamp":1750832896828,"user_tz":-540,"elapsed":9,"user":{"displayName":"이서","userId":"13175179982189425886"}},"outputId":"5e4221fa-b90c-444e-a57f-3459054688fc"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'gpt-4.1': {'input': 2.0, 'output': 8.0},\n"," 'gpt-4.1-mini': {'input': 0.4, 'output': 1.6},\n"," 'gpt-4.1-nano': {'input': 0.1, 'output': 0.4},\n"," 'o1': {'input': 2.0, 'output': 8.0},\n"," 'o3': {'input': 2.0, 'output': 8.0},\n"," 'o4-mini': {'input': 1.1, 'output': 4.4},\n"," 'gpt-4o': {'input': 2.5, 'output': 10.0},\n"," 'gpt-4o-mini': {'input': 0.15, 'output': 0.6}}"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":[],"metadata":{"id":"yQY-WWiYw-V2"},"execution_count":null,"outputs":[]}]}